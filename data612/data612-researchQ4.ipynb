{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data612 - research discussion # 4\n",
    "# by: Sang Yoon (Andy) Hwang\n",
    "# date: 2019-07-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.wired.com/story/creating-ethical-recommendation-engines/ \n",
    "\n",
    "The writer thinks that tech firms are creating recommender system for the favor of profit, not ethics. I would kind of disagree with the content as he/she is missing the point of recommender system in general. I do understand that he/she might not have concrete understanding of recommender system in general so he/she is pretty much fully based on non-technical aspects of recommender system. Implementing \"ethics\" on AI is almost always not possible. Hence, recommending someone ISIS related video does not mean AI is unethical, rather AI was doing its best job or prediction given the inputs. Of course, you may try to filter out some of those unethical meterials and hence not recommend them to users by configuring parameters manually. Configuring parameters, however, is extensive process and almost always will you have edge cases meaning that you will have unethical contents popping up no matter how much you try to get rid of them. \n",
    "\n",
    "Rather, one solution to create somewhat \"ethical\" engine is to educate users how things are working and what they should be expecting from the algorithm. You will always have \"edge\" cases as nothing is perfect. Even manual human validation process (manually click contents you want to watch) will also cause some problems here and there. If humans are not perfect, why doe we \"expect\" AIs to be perfect? And what is the true definition of being perfect? Making \"mistake\" by machine is not necessarily \"mistake\" but it is just that \"AI\" did what it had to do; unlike humans, they do not have sense of morality or sort of \"free style\" thinking system. AI is a simple guy, you feed them something and they return to you exactly what it should.\n",
    "\n",
    "Humans need to revamp their expectation as to how AI should work first before discussing and hoping \"wrong\" expectations."
    "\n",
    "Not only that, Youtube already has sort of filtering mechanism for violent contents; it warns you in advance and make sure you are over 19 to proceed to the content. If we want to sort of "prevent" users to experience violent or abusive contents, just give them warning message and humans will decide what to do next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
